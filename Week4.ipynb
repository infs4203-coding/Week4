{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14daf7e",
   "metadata": {},
   "source": [
    "The main purpose of this document is to introduce how to apply two classifiers, **kNN** and **Naive Bayes**, implemented by [scikit-learn](https://scikit-learn.org/stable/). We will use the modified Iris dataset introduced in previous weeks, and assume we have already completed the imputation, normalization and one-hot encoding. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a911e1d",
   "metadata": {},
   "source": [
    "## 1.Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea2d811",
   "metadata": {},
   "source": [
    "We first import the packages that will be used in this document.\n",
    "\n",
    "1. [Pandas](https://pandas.pydata.org/): Pandas is an open-source Python library widely used for data manipulation, analysis, and cleaning tasks. The central data structure in Pandas is the [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) which provides methods to facilitate the preliminary examination of essential properties, statistical summaries, and a select number of rows for a cursory exploration of the data.\n",
    "\n",
    "2. [Numpy](https://numpy.org/): Numpy is a powerful Python library for numerical and array-based computing. It provides support for large, multi-dimensional arrays and matrices, along with a wide range of mathematical functions to operate on these arrays efficiently. \n",
    "\n",
    "3. [sklearn.neighbors.KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html): KNeighborsClassifier is a class provided by scikit-learn, used to create a k-NN classification model.\n",
    "\n",
    "4. [sklearn.naive_bayes.GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html): GaussianNB is a class provided by scikit-learn, which implements the Gaussian Naive Bayes algorithm.\n",
    "\n",
    "5. [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics): sklearn.metrics includes performance metrics functions used to evaluate a classifier's performance.\n",
    "\n",
    "6. [sklearn.model_selection.cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html): is a function provided by scikit-learn that facilitates performing cross-validation on a given model to evaluate its performance. \n",
    "\n",
    "7. [sklearn.model_selection.GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html): GridSearchCV is a class provided by scikit-learn that facilitates hyperparameter tuning for models using a technique called grid search with cross-validation.\n",
    "\n",
    "These packages will be utilized in following tasks for data loading, classification and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f71a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1007a030",
   "metadata": {},
   "source": [
    "First, we load the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb3dacd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris_modified_train.csv')\n",
    "df_test = pd.read_csv('iris_modified_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a794753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.iloc[:,:-1].values\n",
    "y_train = df.iloc[:,-1].values\n",
    "X_test = df_test.iloc[:,:-1].values\n",
    "y_test = df_test.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892617b4",
   "metadata": {},
   "source": [
    "## 2. Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df39af13",
   "metadata": {},
   "source": [
    "### 2.1 kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d572289",
   "metadata": {},
   "source": [
    "For conducting kNN classification, we use the [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) provided by scikit-learn.\n",
    "\n",
    "The parameter `n_neighbors` represents the important hyperparameter of kNN, the number of neighbours k. By default, it is set to `5`. Changing the value of it would control the learning process. We will introduce later on tuning this hyperparameter.\n",
    "\n",
    "The parameter `metric` shows the method of distance computation. By default, it is set to `minkowski`, which results in the standard Euclidean distance when the other parameter `p` is set to 2.\n",
    "\n",
    "The parameter `p` is the power parameter for the Minkowski metric. By default, it is set to `2`. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2.\n",
    "\n",
    "We will use standard Euclidean distance to build the model in this file. Feel free to explore other distance metrics to better understand their effects on kNN classification in our analysis.\n",
    "\n",
    "First, let's have a look at how the kNN classifier performs on the default `n_neighbors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e2a9af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN_5 = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3152aeae",
   "metadata": {},
   "source": [
    "The [fit()](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.fit) method is a fundamental function in scikit-learn's machine learning models used for training the model on the provided training data.\n",
    "\n",
    "However, the `fit()` method for kNN is different from those discussed last week. It simply stores the training data for reference when performing predictions instead of creating a generalisable model because the kNN classifier is a lazy learning approach as introduced in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5f8bf2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kNN_5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b35d31a",
   "metadata": {},
   "source": [
    "Then, we classify the test data by [predict()](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33319948",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_kNN = kNN_5.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff2d70c",
   "metadata": {},
   "source": [
    "Using the method introduced before, we can evaluate the test performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a4cc6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy of decision tree on the dataset is:  0.868421052631579\n"
     ]
    }
   ],
   "source": [
    "acc_kNN = metrics.accuracy_score(y_test, y_pred_kNN)\n",
    "print(\"The test accuracy of decision tree on the dataset is: \", acc_kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65fe01d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test macro f1-score of decision tree on the dataset is:  0.8758620689655173\n"
     ]
    }
   ],
   "source": [
    "f1_kNN = metrics.f1_score(y_test, y_pred_kNN, average='macro')\n",
    "print(\"The test macro f1-score of decision tree on the dataset is: \", f1_kNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15716499",
   "metadata": {},
   "source": [
    "#### 2.1.1 Cross Validation for Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f672291c",
   "metadata": {},
   "source": [
    "However, in practical scenarios, acquiring the ground truth for the test dataset is often unfeasible. To overcome this, we employ cross-validation, which provides a more reliable estimate of our model's accuracy when test data is not available.We will use the [cross_val_score()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) to evaluate a classifier by cross validation. \n",
    "\n",
    "First, we employ 5-fold cross-validation on the model with k = 5 to evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56687e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validation accuracy is: 0.9019762845849802\n",
      "The cross-validation f1-score is: 0.8960523028170087\n"
     ]
    }
   ],
   "source": [
    "acc_kNN_5 = cross_val_score(kNN_5, X_train, y_train, cv=5, scoring=('accuracy'))\n",
    "f1_kNN_5 = cross_val_score(kNN_5, X_train, y_train, cv=5, scoring=('f1_macro'))\n",
    "print(\"The cross-validation accuracy is: {:}\\nThe cross-validation f1-score is: {:}\".format(acc_kNN_5.mean(), f1_kNN_5.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a682a1",
   "metadata": {},
   "source": [
    "Then let's have a look at the performance of the model with k = 3 by 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "113d5f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validation accuracy is: 0.9023715415019762\n",
      "The cross-validation f1-score is: 0.8950534759358287\n"
     ]
    }
   ],
   "source": [
    "kNN_3 = KNeighborsClassifier(n_neighbors = 3)\n",
    "acc_kNN_3 = cross_val_score(kNN_3, X_train, y_train, cv=5, scoring=('accuracy'))\n",
    "f1_kNN_3 = cross_val_score(kNN_3, X_train, y_train, cv=5, scoring=('f1_macro'))\n",
    "print(\"The cross-validation accuracy is: {:}\\nThe cross-validation f1-score is: {:}\".format(acc_kNN_3.mean(), f1_kNN_3.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339e60b8",
   "metadata": {},
   "source": [
    "Obviously, the `kNN` classifier's performance varies with different hyperparameter values for `k`. \n",
    "\n",
    "To improve the score we can consider tuning some hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330fd1ab",
   "metadata": {},
   "source": [
    "#### 2.1.2 Cross Validation for Tuning Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9460252",
   "metadata": {},
   "source": [
    "[Scikit-learn](https://scikit-learn.org/stable/) provides a function called [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) which will perform a grid search across the parameter space you define. \n",
    "\n",
    "The parameter determines the parameter space of `GridSearchCV` is `param_grid`. It should be in the form of a dictionary or a list of dictionaries.\n",
    "\n",
    "We define parameter search space for `k` as an array of odd numbers between 1 and 21, and make it into the the required form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a274b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [{'n_neighbors': [int(x) for x in np.arange(1, 22, 2)]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8a526e",
   "metadata": {},
   "source": [
    "Then we create kNN models, evaluating their performance using 5-fold cross validation, and then returning the best performing model on macro-F1 and the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bb3c50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 11}\n"
     ]
    }
   ],
   "source": [
    "kNN = KNeighborsClassifier()\n",
    "clf_best_kNN = GridSearchCV(kNN, parameters, cv=5, scoring='f1_macro')\n",
    "clf_best_kNN.fit(X_train, y_train)\n",
    "print(clf_best_kNN.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad917bc9",
   "metadata": {},
   "source": [
    "Empolying the kNN classifier with the best parameter selected, we can further see its cross-validation performance by accuracy and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b13b8129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validation accuracy is: 0.9197628458498024\n",
      "The cross-validation f1-score is: 0.9160363819187347\n"
     ]
    }
   ],
   "source": [
    "kNN_11 = KNeighborsClassifier(n_neighbors = 11)\n",
    "acc_kNN_11 = cross_val_score(kNN_11, X_train, y_train, cv=5, scoring=('accuracy'))\n",
    "f1_kNN_11 = cross_val_score(kNN_11, X_train, y_train, cv=5, scoring=('f1_macro'))\n",
    "print(\"The cross-validation accuracy is: {:}\\nThe cross-validation f1-score is: {:}\".format(acc_kNN_11.mean(), f1_kNN_11.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc92787",
   "metadata": {},
   "source": [
    "Fit the kNN classifier from the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30d14d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kNN_11.fit(X_train, y_train)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b40e1f",
   "metadata": {},
   "source": [
    "Then, we classify the test data by [predict()](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20c1d17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_kNN_11 = kNN_11.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8477505e",
   "metadata": {},
   "source": [
    "Using the method introduced before, we can evaluate the test performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bace425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy of decision tree on the dataset is:  0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "acc_kNN_11 = metrics.accuracy_score(y_test, y_pred_kNN_11)\n",
    "print(\"The test accuracy of decision tree on the dataset is: \", acc_kNN_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc851e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test macro f1-score of decision tree on the dataset is:  0.9488636363636364\n"
     ]
    }
   ],
   "source": [
    "f1_kNN_11 = metrics.f1_score(y_test, y_pred_kNN_11, average='macro')\n",
    "print(\"The test macro f1-score of decision tree on the dataset is: \", f1_kNN_11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf73bd26",
   "metadata": {},
   "source": [
    "We can observe that compared to the case setting `n_neighbors=5`, the test performance have increased when setting `n_neighbors` to 11, a hyperparameter selected by cross-validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa91b23d",
   "metadata": {},
   "source": [
    "### 2.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cc4843",
   "metadata": {},
   "source": [
    "We utilize the [GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html) provided in scikit-learn for our classification tasks for Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8031e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec410197",
   "metadata": {},
   "source": [
    "Given that no particular hyperparameter necessitates tuning in this model, we proceed to directly fit it using the training dataset by [fit()](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB.fit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4632cbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261c3606",
   "metadata": {},
   "source": [
    "We employ 5-fold cross-validation on the model to evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd5eeaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validation accuracy is: 0.8747035573122529\n",
      "The cross-validation f1-score is: 0.8679511664805781\n"
     ]
    }
   ],
   "source": [
    "acc_gnb = cross_val_score(gnb, X_train, y_train, cv=5, scoring=('accuracy'))\n",
    "f1_gnb = cross_val_score(gnb, X_train, y_train, cv=5, scoring=('f1_macro'))\n",
    "print(\"The cross-validation accuracy is: {:}\\nThe cross-validation f1-score is: {:}\".format(acc_gnb.mean(), f1_gnb.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09b2d3a",
   "metadata": {},
   "source": [
    " We proceed with the process to observe the outcome. We classify the test data by [predict()](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB.predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7edb423",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gnb = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835fc820",
   "metadata": {},
   "source": [
    "And we evaluate by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61ca567c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy of decision tree on the dataset is:  0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "acc_gnb = metrics.accuracy_score(y_test, y_pred_gnb)\n",
    "print(\"The test accuracy of decision tree on the dataset is: \", acc_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6268c10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test macro f1-score of decision tree on the dataset is:  0.9488636363636364\n"
     ]
    }
   ],
   "source": [
    "f1_gnb = metrics.f1_score(y_test, y_pred_gnb, average='macro')\n",
    "print(\"The test macro f1-score of decision tree on the dataset is: \", f1_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ead24c",
   "metadata": {},
   "source": [
    "Author: *Kaki Zhou* 8/8/2024 "
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Kaki Zhou"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
